{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy as tp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pycountry\n",
    "import re\n",
    "import string\n",
    "import networkx\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# consumer_key = \"gy8qOgm0gHteI1qXLeVDuDlub\"\n",
    "# consumer_key_private = \"bbwhmpswqnBUYCaVY7Ob376fp8JxXZBPoNT04j1GlMZJnrMQFK\"\n",
    "\n",
    "# access_token = \"1320072218764840967-MwlsT99Myns1jaV6cxL3kXdAZzBvBa\"\n",
    "# access_token_secret=\"4FbBu81heV9ysTxCOCTZqqYYcZRIQ9sAuGFfHFl5Fa1bt\"\n",
    "\n",
    "bearer = \"AAAAAAAAAAAAAAAAAAAAANiRawEAAAAAfKNPCYMcniELb5kd8juRmgEuuCo%3D2aNn5aDumryhqQVqXtxLeVL3T7v0dJD3p18tRbJtehWIWbzTAF\"\n",
    "\n",
    "\n",
    "# client = tp.Client(\n",
    "#     consumer_key=consumer_key, consumer_secret=consumer_key_private,\n",
    "#     access_token=access_token, access_token_secret=access_token_secret\n",
    "# )\n",
    "\n",
    "client = tp.Client(bearer)\n",
    "\n",
    "enList = []\n",
    "zoekWoord = \"#abortion\"\n",
    "\n",
    "response = client.search_recent_tweets(query = zoekWoord, tweet_fields=\"lang\", place_fields=\"contained_within,country,country_code,full_name,geo,id,name,place_type\" ,max_results=25)\n",
    "\n",
    "for tweet in response.data:\n",
    "\n",
    "    if(tweet.lang == \"en\"):\n",
    "        enList.append(tweet.text)\n",
    "\n",
    "    \n",
    "    for tweet in enList:\n",
    "        print(tweet)\n",
    "\n",
    "def verwijderLidWoorden(unorderedList):\n",
    "    for tweet in unorderedList:\n",
    "        tweet = tweet.lower()\n",
    "        tweet = tweet.replace(\" the \", \"\")\n",
    "        tweet = tweet.replace(\" a \", \"\")\n",
    "        tweet = tweet.replace(\" an \", \"\")\n",
    "        print(tweet)\n",
    "\n",
    "\n",
    "\n",
    "def haalWoordFrequentyOp(orderedList):\n",
    "    all_tweets = orderedList\n",
    "\n",
    "    all_tweets[:5]\n",
    "\n",
    "        # definieer de methode om urls uit de tweet te verwijderen\n",
    "    def remove_url(txt):\n",
    "        return \" \".join(re.sub(\"([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \"\", txt).split())\n",
    "\n",
    "    # verwijder de urls en stop de tweets zonder url in een lijst\n",
    "    all_tweets_no_urls = [remove_url(tweet) for tweet in all_tweets]\n",
    "    all_tweets_no_urls[:5]\n",
    "\n",
    "    # split de woorden van een tweet in unieke elementen en maak deze lowercase\n",
    "    all_tweets_no_urls[0].lower().split()\n",
    "\n",
    "    # maak een lijst van lijsten die lowercase woorden bevatten voor elke tweet\n",
    "    words_in_tweet = [tweet.lower().split() for tweet in all_tweets_no_urls]\n",
    "    words_in_tweet[:2]\n",
    "\n",
    "    # maak een lijst van alle woorden uit alle tweets\n",
    "    all_words_no_urls = list(itertools.chain(*words_in_tweet))\n",
    "\n",
    "    # maak een counter\n",
    "    counts_no_urls = collections.Counter(all_words_no_urls)\n",
    "\n",
    "    print(counts_no_urls.most_common(15))\n",
    "\n",
    "    # stop de schone tweets zonder urls in een dataframe en toon deze op het scherm\n",
    "    clean_tweets_no_urls = pd.DataFrame(counts_no_urls.most_common(15),\n",
    "                                columns=['words', 'count'])\n",
    "\n",
    "    clean_tweets_no_urls.head()# stop de schone tweets zonder urls in een dataframe en toon deze op het scherm\n",
    "    clean_tweets_no_urls = pd.DataFrame(counts_no_urls.most_common(15),\n",
    "                                columns=['words', 'count'])\n",
    "\n",
    "    print(clean_tweets_no_urls.head())\n",
    "\n",
    "    # plot de horizontale grafiek\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    clean_tweets_no_urls.sort_values(by='count').plot.barh(x='words',\n",
    "                        y='count',\n",
    "                        ax=ax,\n",
    "                        color=\"purple\")\n",
    "\n",
    "    ax.set_title(\"Common Words Found in Tweets (Including All Words)\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "verwijderLidWoorden(enList)\n",
    "haalWoordFrequentyOp(enList)\n",
    "\n",
    "##Individuele opdracht Jesse & Imran\n",
    "#Sentiment Analysis\n",
    "def auth():\n",
    "    return bearer\n",
    "\n",
    "def create_url(query, max_results, next_token):\n",
    "    query = query\n",
    "    max_results = '100'\n",
    "    url = \"https://api.twitter.com/2/tweets/search/recent?query={}&tweet.fields=author_id,lang,created_at&max_results={}\".format(query, max_results)\n",
    "    if next_token: \n",
    "        url = \"https://api.twitter.com/2/tweets/search/recent?query={}&tweet.fields=author_id,lang,created_at&max_results={}&next_token={}\".format(query, max_results, next_token)\n",
    "    return url\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(url, headers):\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def get_tweets(query, max_results, next_token=None):\n",
    "    bearer_token = auth()\n",
    "    url = create_url(query, max_results, next_token)\n",
    "    headers = create_headers(bearer_token)\n",
    "    json_response = connect_to_endpoint(url, headers)\n",
    "    return json.dumps(json_response, indent=4, sort_keys=True)\n",
    "query = \"Arsenal Edu lang:en -is:retweet\"\n",
    "limit = \"100\"\n",
    "tweet_list = []\n",
    "next_token = \"\"\n",
    "\n",
    "for i in range(20):\n",
    "    data = get_tweets(\n",
    "        query, \n",
    "        limit,\n",
    "        next_token\n",
    "    )\n",
    "    data = json.loads(data)\n",
    "    next_token = data['meta']['next_token']\n",
    "    tweet_list += data['data']\n",
    "\n",
    "tweets_df = pd.DataFrame(tweet_list)\n",
    "tweets_df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "['#moederdag #genieten https://t.co/JsQSv3l8VW', 'RT @DierenRecht: Voor moederkoeien in de zuivelindustrie valt er weinig te vieren op #Moederdag. Zowel hun kalfjes als hun moedermelk worde‚Ä¶', 'RT @Wdekanter: #moederdag\\nVoor alle moeders √©n voor hen zonder moeder, of voor hen die hun moeder dreigen te verliezen. Voor de moeders die‚Ä¶', 'RT @agilityfanatic: √ì√≥k #dieren zijn moeder. #moederdag. https://t.co/zOjBJZ3EJC', 'RT @Sasklei: Over #moederdag gesproken: Studiegenoot Anne maakte deze prachtige korte documentaire. Ze worstelt met de acceptatie van haar‚Ä¶', 'RT @geertwilderspvv: Goedemorgen Nederland en een hele fijne  #moederdag vandaag! \\n\\n‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è https://t.co/5M3RMNFv5j', 'RT @QQHaseena: Horrorpolitiek \\n\\n#hugo #buitenhof #WNLopzondag #moederdag', '#moederdag https://t.co/tiZJOFh4zw', 'Genieten #pathe #piraten #movie #moederdag @ Path√© Schiedam https://t.co/5CnNQlsPBF', 'RT @KAFKA_Dev: Ik heb op deze #moederdag maar 1 vraag: WAAR zijn die 1115, door de overheid ONTVOERDE kinderen? \\n\\nBreng ze TERUG!!!', 'RT @KAFKA_Dev: Ik heb op deze #moederdag maar 1 vraag: WAAR zijn die 1115, door de overheid ONTVOERDE kinderen? \\n\\nBreng ze TERUG!!!', 'Er zijn dagen, weken dat ik niet aan haar denk maar moederdag!\\nAl 33 jaar zonder haar. Waar blijft de tijd #moederdag', 'RT @KAFKA_Dev: Ik heb op deze #moederdag maar 1 vraag: WAAR zijn die 1115, door de overheid ONTVOERDE kinderen? \\n\\nBreng ze TERUG!!!', 'Heel sympathiek, een #moederdag bezoekje aan moeder of in dit geval zieke oma maar GEEN geldige om tijdens de #zondagsrust op #Urk buiten te zijn! #Bekeuring #DuurBosjeBloemen https://t.co/w0AuM6Bn07', 'RT @KAFKA_Dev: Ik heb op deze #moederdag maar 1 vraag: WAAR zijn die 1115, door de overheid ONTVOERDE kinderen? \\n\\nBreng ze TERUG!!!', 'Do you wanna have your own #Mothersday #moederdag next year? Ill be glad to help you ü•∞ü•∞ü•∞ü•∞üçÜüçÜüçÜüçÜüí¶üí¶üí¶üí¶üí¶ https://t.co/lQ3JIv4VIe', '#moederdag https://t.co/wgp1OJRb3A', 'Let s commit to save our mother soil.\\n#moederdag #savesoil #ConsciousPlanet https://t.co/dgerfcRgVO', \"Voor alle mama's  en bonus mama's  #moederdag https://t.co/0VxYqEF09y\", 'RT @agilityfanatic: √ì√≥k #dieren zijn moeder. #moederdag. https://t.co/zOjBJZ3EJC', 'RT @KAFKA_Dev: Ik heb op deze #moederdag maar 1 vraag: WAAR zijn die 1115, door de overheid ONTVOERDE kinderen? \\n\\nBreng ze TERUG!!!', 'RT @KAFKA_Dev: Ik heb op deze #moederdag maar 1 vraag: WAAR zijn die 1115, door de overheid ONTVOERDE kinderen? \\n\\nBreng ze TERUG!!!']\n"
     ]
    }
   ],
   "source": [
    "# individuele opdracht Jelle\n",
    "zoekWoord = \"#moederdag\"\n",
    "aantal = 0\n",
    "lijst = []\n",
    "\n",
    "responseJelle = client.search_recent_tweets(query = zoekWoord, tweet_fields=\"lang\", \n",
    "place_fields=\"contained_within,country,country_code,full_name,geo,id,name,place_type\" ,max_results=25)\n",
    "\n",
    "for tweet in responseJelle.data:\n",
    "        if \"moeder\" in tweet.text:\n",
    "                aantal += 1\n",
    "                lijst.append(tweet.text)\n",
    "\n",
    "print(aantal)\n",
    "print(lijst)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ded6747eff3de8991bd43867c4116e771eb7e6d01e29916673c2b74b5d35c956"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
